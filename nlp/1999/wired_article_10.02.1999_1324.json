{"URL": "https://www.wired.com/1999/10/superhuman-speech-machine", "heading": "superhuman speech machine", "subheading": "researchers claim a breakthrough in neural networks will lead to superhuman speech recognition systems. by leander kahney.", "author": "leander kahney", "category": "science", "type": "article", "timestamp": "10.02.1999 03:00 AM", "text": "two biomedical engineers claim to have created the first \"superhuman\" speech recognition system following a breakthrough in neural network technology. researchers at the university of southern california say they have developed a system markedly better than people at recognizing spoken speech.if the claims pan out, the system may herald a new era of neural network computing, which has languished for a decade after failing to deliver on the promise of software that mimics human intelligence.however, speech recognition experts warn that the technology hasn't yet been presented in detail to the research community and most are highly skeptical.developed by biomedical engineering professor theodore berger and jim-shih liaw, director of the university's laboratory for neural dynamics, the berger-liaw neural network speaker independent speech recognition system (srs) for the first time displayed better-than-human performance in word recognition tests.according to the researchers, the srs dramatically outperformed an off-the-shelf word recognition system as well as human listeners, showing an uncanny ability to pick out keywords almost completely drowned out by white noise.speaking by phone from his home, berger said the new technology may lead to smaller, faster neural nets that outperform their predecessors to the extreme.a new generation of small neural nets could make voice-activated computer interfaces a reality, berger said, and lead to robust, error-free dictation systems; better hearing aids and implants for the hearing-impaired; and highly adaptive robot control systems.he said the technology may also be adapted for intelligent searches of multimedia databases, and that the us navy is researching its ability to enhance sonar systems.berger said he and liaw are talking with companies interested in commercializing the technology. they hope that within six months, consumers may see hands-free cell phones tolerant of loud noise and even human conversation, which confuse current systems, he said.neural nets simulate biological nervous systems, consisting of mathematical models of neurons and the connections between them.unlike conventional software, they aren't programmed, but trained to associate patterns of input with outputs.like biological systems, neural nets are highly adaptive, cope well with incomplete information and noise, and are suited to complex pattern recognition tasks like identifying words.however, after a flurry of activity in the 80s, neural nets fell out of fashion after failing to create truly artificially intelligent software, as boosters had predicted.incredibly, berger said the srs's superhuman performance is the result of implementing a fairly obvious feature that had previously been overlooked.berger, a neurobiologist by training, said he and liaw realized that a crucial characteristic of biological nervous systems -- the ability of neurons to change their behavior according to the timing of input signals -- had never before been implemented in neural nets.\"it's hard to believe, i know,\" he said. \"but there it is.\"in berger and liaw's model, the timing of inputs are crucial. a neuron may fire if two input signals come very close together, but will not fire if the same two signals are just slightly further apart.thanks to this, the srs comprises just 11 neurons and 30 links. by contrast, previous attempts to build word-recognizing neural nets required hundreds of nodes and thousands of connections, berger said.\"it's just wonderful what you can do with a small number of neurons,\" berger said. \"it's just amazing. we've haven't even started to make them complicated. it's going to be really interesting.\"although the system was trained on only 12 different words and tested with eight different speakers, berger said he was confident it could learn a much larger vocabulary.two major advantages over today's commercial systems, berger said, is that the srs is speaker-independent -- it can recognize a word regardless of who says it -- and it never gives false-positive readings. if the system doesn't recognize a word, it doesn't hazard a guess.bob shannon, director of implant research at the house ear institute in los angeles -- which specializes in developing technology to combat hearing impairment -- said berger and liaw's work represented the first major advance in speech recognition in 30 years.\"speech recognition technology hasn't improved theoretically since the 60s,\" he said. \"yes, they're smaller, cheaper and faster, but the improvements have been pure brute force. [berger and liaw's work] puts a new twist on the traditional network model and the improvement in performance is nothing short of dramatic.\"\"i'm very excited about the system,\" he added. \"i think potentially it's a big breakthrough.\"however, steven greenberg, a speech recognition expert at the international computer science institute in berkeley, california, said in the absence of detailed technical information, berger and liaw's claims are premature.\"i'm skeptical,\" he said. \"let's wait and see. i'm not saying it's not possible but i'd like to see more first.\"in particular, greenberg said the system has a very limited vocabulary and has been tested only in optimum laboratory conditions. he said the system will have to tackle a series of standard speech recognition tests before he was convinced of its validity.\"for anyone in automatic speech research to take them seriously, it would have to be evaluated on a much more comprehensive set of speech materials,\" he said.likewise, jakob nielsen, co-founder of the nielsen norman group, a usability consultancy in mountain view, california, said the system had limited recognition capabilities and showed no ability to understand connected speech rather than individual words.\"something that can be used for a small number of words in very limited interactions can still be very useful,\" he said. \"it's just not at all what's necessary for a star trek computer.\""}