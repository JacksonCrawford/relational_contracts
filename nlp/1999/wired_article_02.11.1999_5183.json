{"URL": "https://www.wired.com/1999/02/the-super-duper-hypercomputer", "heading": "the super-duper hypercomputer", "subheading": "an obscure utah company introduces hal: a computer about the size of most pcs, but a blazing 60,000 times faster. skeptics abound. by christopher jones.", "author": "christopher jones", "category": "science", "type": "article", "timestamp": "02.11.1999 03:00 AM", "text": "a small utah-based company made its first technology announcement this week, and what an announcement it was: star bridge systems claims that it has developed the fastest, most flexible computer architecture in the world, which will be used as the basis for everything from web servers to toasters in the future. star bridge recently completed tests on its new \"hypercomputer,\" a supercomputer it claims is faster and more versatile than any others on the market. called hal, the hypercomputer tested at a rate of 12.84 trillion calculations per second (teraops) \ufffd- equivalent to 60,000 times the speed of a 350-megahertz pc. even better, hal is the size of a normal pc, weighs less than 150 pounds, and plugs into a normal wall outlet.\"this system is not only smaller, but also a lot cheaper and runs on less power [than other supercomputers],\" said brent ward, executive vice president of star bridge. \"it applies across the realm of information technology and electronics. most devices with a chip in them will be using our technology to do things faster in a smaller space -\ufffd from toasters to vcrs to automobiles.\"by comparison, ibm's blue pacific, one of the fastest supercomputers built to date, performs about 3.9 trillion calculations per second and is used for nuclear-weapons simulations at the lawrence livermore lab in california.\"it's like a b western,\" said david schwoegler, a spokesman at the lawrence livermore laboratory. \"when you get a reputation for being fast, everyone wants to take a shot at you.\"several observers noted that star bridge measured its hal computer using different benchmarks than the ibm computer. and, as yet, hal hasn't been tested with real live applications.gregory benson, an assistant professor of computer science at the university of san francisco, explained that star bridge appears to have estimated its performance figures based on a 4 bit integer add operation, which is a much less intensive calculation than a 64 bit floating point operation.supercomputers are normally measured in terms of flops, or floating point operations per second. thus, the star bridge measurement of 12.8 teraops is not directly comparable to the ibm-asci blue-pacific measurement of 1.2 teraflops, he said.\"i wouldn't be swayed until i see an application running on it,\" benson added.though its claims have been met with skepticism, the company's founder, kent gilson, said he has spent 15 years hacking out code for such a \"re-configurable\" computing design and has developed products in the past that incorporate it. in the 1980s, he created a 128-channel add-in board for sound mixing on pcs, and since about 1987, has been working on the software design for hal.hal's fundamental architecture is based on field-programmable gate array (fpga) chips, essentially blank pieces of silicon that can be reprogrammed an infinite number of times. xilinx corp. invented fpgas about 15 years ago and has provided star bridge with free chips and technical support to build its hal machines.\"there are lots of research picking up steam now on fpgas,\" said mike seither, a spokesman for xilinx. \"a number of companies have commercial applications now, taking advantage of them. ibm is using fpgas in switches for atm networks.\"since the standard for creating atm is in flux, he said, ibm created fpga circuits that can be reconfigured remotely when the standard is hashed out.the hal computer has 280 xilinx chips on 36 proprietary integrated circuit boards. star bridge has also developed its own software system, viva, which is an operating system with programming tools to develop specific applications. the hal will cost about us$26 million, and the company has 120 programmers to build the customized applications for each machine it sells.one thing that makes his system so fast is the hierarchical arrangement of the fpgas, which provides more control over the information-carrying components of the system.\"you can configure the memory any way you want. each fpga has a distinct memory environment, but you can have those memories any way you want,\" he said. \"you could have one master processor or one part of one processor accessing any other part. you have fine-grain control down to the bit level.\"gilson said his company has deals in the works with several telecom and pharmaceutical manufacturers and is interested in developing rendering systems for hollywood and geophysical visualization systems for oil companies. the first application under design is a pattern matching algorithm for gene searching and predictive biological systems engineering, he said.undaunted by the likes of ibm and cray, gilson said he expects to take the world by storm when the system is demonstrated, running real applications, later this year.\"it will be some time before people will believe this is real. but in six to eight months, it will be an even bigger story, when the applications roll out,\" he said. \"it will take this economic process before it will happen.\""}